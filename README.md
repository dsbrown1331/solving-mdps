# solving-mdps
Homework on value and policy iteration.

Turn in one written report per group via Canvas with all group members names on the report. Also turn in your code.

This section of the Sutton and Barto RL book is a good supplement to go along with the class slides:
http://incompleteideas.net/book/ebook/node40.html


## Part 1: 
Finish `homework3.py` by filling in the relevant methods in `mdp_utils.py`. We've provided you with some gridworld starter code and a simple MDP class in `mdp.py`.

When you finish, you should get the same results from both Value Iteration and Policy Iteration.

In your report include the output of `homework2.py`.

## Part 2:
Play around with the MDP and change some things and report on what happens. For example, maybe change the reward function, change the noise in the MDP, change the terminal states. Does the change in the optimal policy make sense? Report on two different changes you made that resulted in a different optimal policy than you got in Part 1. 
